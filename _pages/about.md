---
permalink: /
title: "Jack Koch"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I graduated from Yale with a B.S. in Applied Mathematics and a concentration in Computer Science in May 2019. At Yale, I conducted NLP research under the supervision of Professor Dragomir Radev in the [Language, Information, and Learning at Yale (LILY) Lab](https://yale-lily.github.io/).

Since then, I've been doing technical AI safety and alignment research. I co-led a project at the [AI Safety Camp](https://aisafety.camp) that produced the first empirical demonstrations of a new kind of robustness failure, [failures of objective robustness](https://arxiv.org/abs/2105.14111). I recently wrapped up a summer fellowship at the [Center on Long-term Risk](https://longtermrisk.org), where I sought to understand takeaways from [Dennett's intentional stance](https://www.alignmentforum.org/posts/jHSi6BwDKTLt5dmsG/grokking-the-intentional-stance) and [the human brain itself](https://www.alignmentforum.org/posts/6chtMKXpLcJ26t7n5/integrating-three-models-of-human-cognition) for thinking about agency in the context of AI safety. Now, I'm applying to PhD programs, where I hope to do empirical ML alignment research.
